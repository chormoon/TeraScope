---
title: "report"
author: "Yang Cong"
date: "2022/1/20"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
knitr::opts_chunk$set(fig.align = "center")
```

```{r load, include=FALSE}
# Source the code from analysis script in src folder
 library('ProjectTemplate')
 library(hms)
 library(dplyr)
 library(tidyr)
 library(ggplot2)
 load.project()
 source("src/eda.R")
```
# **Introduction**
## **Background**
#### Terapixel images offer an intuitive, accessible way to present information sets to stakeholders, allowing viewers to interactively browse big data across multiple scales. The challenge we addressed here is how to deliver the supercomputer scale resources needed to compute a realistic terapixel visualization of the city of Newcastle upon Tyne and its environmental data as captured by the Newcastle Urban Observatory.

#### Our solution is a scalable architecture for cloud-based visualization that we can deploy and pay for only as needed. The three key objectives of this work are to: create a supercomputer architecture for scalable visualization using the public cloud; produce a terapixel 3D city visualization supporting daily updates; undertake a rigorous evaluation of cloud supercomputing for compute intensive visualization applications.

#### We demonstrate that it is feasible to produce a high quality terapixel visualization using a path tracing renderer in under a day using public IaaS cloud GPU nodes. Once generated the terapixel image supports interactive browsing of the city and its data at a range of sensing scales from the whole city to a single desk in a room, accessible across a wide range of thin client devices.


## **Need for the project**
#### The dataset was created from application checkpoint and system metric output from the production of a terapixel image. There are varieties of problems that can be addressed using the TeraScope dataset. What we need is to use what we learned to explore and analyse the Data.

# **Explore and analyse**
## **Data Process**
#### First, I decide to clean and deduplicate the data. Then look at the first question, that is, 'Which event types dominate task runtimes?'. To solve this question, I count the hostname for each data set and check whether both data set the hostname is the same using the setequal function of dplyr.
#### To get which event dominate task runtimes, we first should create a new data frame to compute the task runtimes and change time to hms format. I also create a new feature called duration which features the running time for each event. The new data frame we finally get is bellow.
```{r echo=FALSE}
head(DurationsNew)
```

#### Then, for the next question: 'What is the interplay between GPU temperature and performance?' We only need the powerDrawWatt gpuTempC gpuUtilPerc and gpuMemUtilPerc. Here we creat three data frames to find out there interplay.
```{r echo=FALSE}
head(data_power_temp)
head(data_gpuUtilPerc_temp)
head(data_gpuMemUtilPerc_temp)
```
#### For question: 'What is the interplay between increased power draw and render time?' We need to find the relationship between power and render time. So I firstly calculate the avg render for each hostname. Then I calculate the avg power for each hostname. Now we can combine the data as bellow.
```{r echo=FALSE}
head(avg_power_render)
```
#### For quesion: 'Can we identify particular GPU cards (based on their serial numbers) whose performance differs to other cards? (i.e. perpetually slow cards)' We should calculate average Task Duration for Each GPU Seria and draw the total render time avg for each host. During this we also need to find out the relation between these differnt data frame to find a correct way to combine them. By checking it is obviously each hostname is a gpu card. So we can continue our calculating and combining. Here I finally draw 10 data so that it can be easier to analysis.
```{r echo=FALSE}
head(host_card)
```
#### Finally the last quesion: 'What can we learn about the efficiency of the task scheduling process?' First we should find out which can be uesd to measure the efficiency. I think the efficiency would be measured by the amount of idle time between tasks. For this analysis we would assess each hostname separately and we would record the total idle time for each hostname. The data would be used to analyse is below.
```{r echo=FALSE}
head(efficiency)
```


## **Data Analysis**
#### For the first question, I use a bar chart to display the running time for each event. It is obviously render dominate task runtimes
```{r echo=FALSE}
# Q1: Which event types dominate task runtimes?
head(DurationsNew,1)
Total_Tiling_time = sum(DurationsNew$Tiling)
Total_Saving_time = sum(DurationsNew$`Saving Config`)
Total_Render_time = sum(DurationsNew$Render)
Total_Uploading_time = sum(DurationsNew$Uploading)
# Set the x_axis and y_axis.
y_duration = c(Total_Tiling_time,Total_Render_time,Total_Saving_time,Total_Uploading_time)
x_duration = c('Total_Tiling_time','Total_Render_time','Total_Saving_time','Total_Uploading_time')
# plot the bar chart
barplot(height = y_duration,
        names.arg = x_duration,
        col = 'orange',
        border = '#ffffff')
# It is obviously render dominate task runtimes
```
#### For the second question, I use three scatter plots to display the relation ship between these variables and a fit line to make the relationship more visible. So the GPU temperature is proportional to performance.
```{r echo=FALSE}

# Q2: What is the interplay between GPU temperature and performance?
# power and temp
p01=ggplot(
       data=data_power_temp, # set data
       mapping=aes( 
             x=c_temp, 
             y=power_avg,
             color= power_avg
         )
   )
p01+geom_point()+theme_bw()+geom_smooth(method="lm",colour= "orange" )+scale_color_gradient(low = "pink", high = "red")
```
```{r echo=FALSE}
# gpuUtilPerc and temp
p02=ggplot(
  data=data_gpuUtilPerc_temp, # set data
  mapping=aes( 
    x=c_temp, 
    y=gpuUtilPerc_avg,
    color=gpuUtilPerc_avg
  )
)
p02+geom_point()+theme_bw()+geom_smooth(method="lm",colour= "orange" )+scale_color_gradient(low = "pink", high = "red")
```

```{r echo=FALSE}
# gpuMemUtilPerc and temp
p03=ggplot(
  data=data_gpuMemUtilPerc_temp, # set data
  mapping=aes( 
    x=c_temp, 
    y=gpuMemUtilPerc_avg,
    color=gpuMemUtilPerc_avg
  )
)
p03+geom_point()+theme_bw()+geom_smooth(method="lm",colour= "orange" )+scale_color_gradient(low = "pink", high = "red")
# So the GPU temperature is proportional to performance 
```

#### For the third question.  I decide to use the hostname as a distinction and compute the avg of the power and render.It also use a scatter plot to display the relationship. It seems that increased power draw means to a longer render.
```{r echo=FALSE}
p04=ggplot(
  data=avg_power_render, # set data
  mapping=aes( 
    x=avg_power_list, 
    y=as.numeric(avg_render_list),
    color=as.numeric(avg_render_list)
  )
)
p04+geom_point()+theme_bw()+geom_smooth(method="lm",colour= "orange" )+scale_color_gradient(low = "pink", high = "red")
```
#### For the forth question, I first check the hostname for each gpu card, otherwise I can not connect the two data frame and so that I can not find out the question. Luckily I managed to find it. Then we can plot the box plot. Here I list the slowest 10 gpu cards.
```{r echo=FALSE}
ggplot(host_card, aes(y=Total_Render_time_avg, x=c_card, fill =  c_card))+
  geom_boxplot() + ggtitle("Event Names Run Time")+scale_x_discrete(guide = guide_axis(n.dodge=3))+
  theme(plot.title = element_text(hjust = 0.05))
```
#### The last question. It is about the amount of idle time between tasks. So I calculate the running time and render time for each GPU card and list them. Then I divide the total run time by the render time, got the efficiency('efficiency_duration' bellow).
```{r echo=FALSE}
 head(efficiency,10)
```


# **Conclusion**
#### Based on the analysis above, we got the ansewers for these questions. It is obviously that the render task  dominate task runtimes and the higher the GPU temperature, the better the performance. The increased power draw symbolizes a longger render time. It is easy for us to identify particular GPU cards by comparing their performance and it is possible for us to calculate the efficiency of each gpu and manage them.

# **Personal Reflections**
#### Undertaking this project has increased my knowledge and develop my skills regarding an area in which I have a special interest. It also develop my skills regarding report writing.
#### During the work, once again I am familiar with the skills of using the R language. And when I get a fit for a bunch of unfamiliar data, I can get to grips with how to analyze them faster. At the same time, this time I also learned to operate on time data, and to link multiple data through a field.

